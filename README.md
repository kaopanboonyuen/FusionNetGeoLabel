# **FusionNetGeoLabel** ğŸŒğŸ›°ï¸

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![DOI: 10.58837/CHULA.THE.2019.158](https://img.shields.io/badge/DOI-10.58837/CHULA.THE.2019.158-blue.svg)](https://digital.car.chula.ac.th/chulaetd/8534/)

## **Overview** ğŸ“š

**FusionNetGeoLabel** is a cutting-edge deep learning framework tailored for semantic segmentation in remotely sensed imagery. This repository is a culmination of my Ph.D. research, aimed at enhancing the accuracy and efficiency of semantic labeling in satellite and aerial images. ğŸš€

One of the fundamental tasks in remote sensing is **semantic segmentation** on aerial and satellite imagery.  
FusionNetGeoLabel introduces a feature-fusion-based **Enhanced Global Convolutional Network** with **high-resolution representations** and **depthwise atrous convolutions** for state-of-the-art performance on remote sensing benchmarks (ISPRS Vaihingen, Potsdam, and Massachusetts Roads).

---

## **Author** âœï¸

**Teerapong Panboonyuen**  
Ph.D. in Computer Engineering, Chulalongkorn University ğŸ“

---

## **Abstract** ğŸ“„

Semantic segmentation is a cornerstone in remote sensing, impacting various domains like agriculture ğŸŒ¾, map updates ğŸ—ºï¸, and navigation ğŸš—. Despite the prominence of Deep Convolutional Encoder-Decoder (DCED) networks, they often falter in capturing low-level features such as rivers and low vegetation due to architectural constraints and limited domain-specific data.

This dissertation presents an advanced semantic segmentation framework designed for remote sensing, featuring five key innovations:

- **Global Convolutional Network (GCN):** ğŸ§  Enhances segmentation accuracy for remote sensing images.
- **Channel Attention Mechanism:** ğŸ¯ Focuses on the most critical features for better performance.
- **Domain-Specific Transfer Learning:** ğŸ› ï¸ Tackles the challenge of limited training data in remote sensing.
- **Feature Fusion (FF):** ğŸ”„ Effectively integrates low-level features into the model.
- **Depthwise Atrous Convolution (DA):** ğŸ” Refines feature extraction for improved segmentation.

Our experiments on private Landsat-8 datasets and the public "ISPRS Vaihingen" benchmark show that the proposed architecture significantly outperforms baseline models. ğŸ“Š

---

## âœ¨ Key Features

- ğŸ›°ï¸ **High-Resolution Feature Fusion** with Atrous Depthwise Convolution  
- ğŸ”¥ **Global Convolutional Blocks** for capturing contextual dependencies  
- âš¡ Mixed Precision Training (AMP) support for fast GPU training  
- ğŸ“¦ Modular PyTorch code with dataset loaders, metrics, and inference scripts  
- ğŸ³ Ready-to-run with **Docker** and **Google Colab**  

---

## ğŸ“œ Repo layout

```
FusionNetGeoLabel/
â”œâ”€â”€ fusionnetgeolabel/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ FusionNetGeoLabel.py
â”‚   â”œâ”€â”€ heads.py
â”‚   â”œâ”€â”€ modules.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data.py
â”‚   â”‚   â”œâ”€â”€ augmentation.py
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â”œâ”€â”€ losses.py
â”‚   â”‚   â”œâ”€â”€ train_utils.py
â”‚   â”‚   â””â”€â”€ tiling.py
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ default.yaml
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_isprs_vaihingen.py
â”‚   â”œâ”€â”€ download_isprs_potsdam.py
â”‚   â””â”€â”€ download_massachusetts_roads.py
â”œâ”€â”€ train.py
â”œâ”€â”€ test.py
â”œâ”€â”€ inference.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## **Publications & Resources** ğŸ“š

- **Ph.D. Thesis:** [Semantic Segmentation on Remotely Sensed Images Using Deep Convolutional Encoder-Decoder Neural Network](https://digital.car.chula.ac.th/chulaetd/8534/) ğŸ“œ
- **Code Repository:** [GitHub - FusionNetGeoLabel](https://github.com/kaopanboonyuen/FusionNetGeoLabel) ğŸ’»
- **Pretrained Models:** [Download Pretrained Models](https://github.com/kaopanboonyuen/FusionNetGeoLabel) ğŸ“¥
- **ISPRS Vaihingen Dataset:** [Download Dataset](https://paperswithcode.com/dataset/isprs-vaihingen) ğŸ—‚ï¸
- **ISPRS Vaihingen Leaderboard:** [Semantic Segmentation Leaderboard](https://paperswithcode.com/sota/semantic-segmentation-on-isprs-vaihingen) ğŸ†

<p align="center">
  <img src="img/GraphicalAbstract.png" alt="Graphical Abstract" width="600"/>
  <img src="img/p2_method_2.png" alt="Method 2" width="600"/>
  <img src="img/p3_method_3.png" alt="Method 3" width="600"/>
</p>

## **How to Use** ğŸ”§

---

## ğŸš€ Getting Started

### 1. Clone Repo
```bash
git clone https://github.com/kaopanboonyuen/FusionNetGeoLabel.git
cd FusionNetGeoLabel
````

### 2. Install Requirements

```bash
python -m venv .venv && source .venv/bin/activate
pip install --upgrade pip -r requirements.txt
```

### 3. Datasets

Supported datasets:

* [ISPRS Vaihingen](https://www2.isprs.org/commissions/comm2/wg4/benchmark/semantic-labeling-vaihingen/) ğŸ™ï¸
* [ISPRS Potsdam](https://www2.isprs.org/commissions/comm2/wg4/2d-sem-label-potsdam/) ğŸŒ³
* [Massachusetts Roads](https://www.cs.toronto.edu/~vmnih/data/) ğŸ›£ï¸

Download scripts are provided:

```bash
python scripts/download_massachusetts_roads.py --out data/mass_roads
```

> âš ï¸ ISPRS datasets require registration and acceptance of terms. Place downloaded `.zip` files into `data/` and the scripts will unpack + tile.

---

## ğŸ‹ï¸ Training

Example: training on Vaihingen dataset

```bash
python train.py \
  --dataset vaihingen \
  --data-dir ./data/vaihingen \
  --batch-size 8 \
  --epochs 100 \
  --lr 0.001 \
  --save-dir ./checkpoints
```

With mixed precision training (faster & memory efficient):

```bash
python train.py --config configs/default.yaml
```

---

## ğŸ” Inference and Testing

Run inference on a large aerial image with sliding-window:

```bash
python inference.py --checkpoint runs/best.ckpt --image path/to/ortho.tif --out out.tif
```

```bash
python test.py --checkpoint runs/last.ckpt --data_dir data/mass_roads
```

---

## ğŸ³ Docker Support

Build and run in Docker:

```bash
docker build -t fusionnet-geolabel .
docker run --gpus all -it fusionnet-geolabel
```

---

## ğŸš€ Sample Results

![](img/out3.png)
![](img/out1.png)
![](img/out5.png)
---

## ğŸ“˜ Citation

If you use this code, please cite:

```bibtex
@phdthesis{panboonyuen2019semantic,
  title  = {Semantic segmentation on remotely sensed images using deep convolutional encoder-decoder neural network},
  author = {Teerapong Panboonyuen},
  year   = {2019},
  school = {Chulalongkorn University},
  type   = {Ph.D. thesis},
  doi    = {10.58837/CHULA.THE.2019.158},
  address= {Faculty of Engineering},
  note   = {Doctor of Philosophy}
}
```

---

## ğŸ† Acknowledgements

* ISPRS Vaihingen & Potsdam Datasets
* Massachusetts Roads Dataset
* PyTorch ecosystem
* Chulalongkorn University â€“ Faculty of Engineering

---